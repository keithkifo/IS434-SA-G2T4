{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IS434: Social Analytics & Apps\n",
    "### SkillsFuture Industry Scraper\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "import aspose.words as aw\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean file names, convert to PDF to HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# fix file names after importing - to be run once only after scraping\n",
    "\n",
    "def clean_title( file_name ):\n",
    "    temp = file_name.replace(\"Skills Map_\", \"\")\n",
    "    temp = temp.replace(\"(GSC Top 5)\", \"\")\n",
    "    temp = temp.split(\" \")\n",
    "    temp = \"-\".join(temp)\n",
    "    temp = temp.replace(\"-.pdf\", \".pdf\")\n",
    "    new_name = temp.lower()\n",
    "    return new_name\n",
    "    \n",
    "# Retrieve each sector\n",
    "sector_dir_list = [ dir for dir in os.listdir(\"./\") if dir.endswith('_Sector') ]\n",
    "\n",
    "for sector_dir in sector_dir_list:\n",
    "    # Retrieve all subsectors in a sector\n",
    "    subsector_dir_list = [ dir for dir in os.listdir(f\"./{sector_dir}\") ]\n",
    "\n",
    "    for subsector_dir in subsector_dir_list:\n",
    "        # Retrieve all pdf files in a subsector\n",
    "        pdf_files = [ file for file in os.listdir(f\"./{sector_dir}/{subsector_dir}/pdf\") if file.endswith(\".pdf\") ]\n",
    "\n",
    "        # Clean each file's title and rename the file\n",
    "        for file in pdf_files:\n",
    "            # Clean file title and rename file\n",
    "            new_name = clean_title( file )\n",
    "            os.rename(f\"./{sector_dir}/{subsector_dir}/pdf/{file}\", f\"./{sector_dir}/{subsector_dir}/pdf/{new_name}\")\n",
    "            \n",
    "            # Save PDF as HTML document\n",
    "            doc = aw.Document(f\"./{sector_dir}/{subsector_dir}/pdf/{new_name}\")\n",
    "            doc.save(f\"./{sector_dir}/{subsector_dir}/html/{new_name[:-4]}.html\")\n",
    "\n",
    "        # Remove images generated from the aspose package (only workaround)\n",
    "        for file in os.listdir(f'./{sector_dir}/{subsector_dir}/html/'):\n",
    "            if file.endswith('.png'):\n",
    "                os.remove(f'./{sector_dir}/{subsector_dir}/html/{file}')\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape the HTML for Job Role + Job Skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to extract job role\n",
    "def retrieve_job_role( span_list ):\n",
    "    for i in range( len(span_list) ):\n",
    "        span_text = span_list[i].text.strip()\n",
    "\n",
    "        if \"Job Role\" == span_text:\n",
    "            return span_list[i+1].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to extract skills\n",
    "def retrieve_skills( span_list ):\n",
    "    end_index = 0\n",
    "    start_index = 0\n",
    "    \n",
    "    # Get index of last occurrence of skill\n",
    "    for i in range( len(span_list)-1, 0, -1 ):\n",
    "        text = span_list[i].text\n",
    "        if \"Level\" in text:\n",
    "            end_index = i\n",
    "            break\n",
    "\n",
    "    # Get index of first occurrence of skill\n",
    "    for i in range( len(span_list)-1 ):\n",
    "        text = span_list[i].text\n",
    "        if \"Generic Skills and Competencies\" in text:\n",
    "            start_index = i+1\n",
    "            break\n",
    "    \n",
    "    # Get the subset of <span> that have the skills\n",
    "    skillsets = [ span.text for span in span_list[start_index:end_index+1] ]\n",
    "\n",
    "    # Remove '\\xa0' occurrences in list from pdf to html conversion\n",
    "    skillsets = [ skill for skill in skillsets if skill.strip() not in \"\\xa0\"]\n",
    "    \n",
    "    # Store as list of skills and return\n",
    "    skills_list = {}\n",
    "    \n",
    "    for i in range(1, len(skillsets), 2):\n",
    "        skill_name = skillsets[i-1].strip()\n",
    "        skill_level = skillsets[i].strip()\n",
    "\n",
    "        if \",\" in skill_level:\n",
    "            skill_level = skill_level.split(\", \")[0]\n",
    "\n",
    "        skills_list[skill_name] = skill_level\n",
    "    return skills_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICT_Sector Strategy and Governance Associate Business Analyst {'Business Environment Analysis': 'Level 2', 'Problem Solving': 'Intermediate', 'Business Needs Analysis': 'Level 2', 'Lifelong Learning': 'Intermediate', 'Business Requirements Mapping': 'Level 3', 'Transdisciplinary Thinking': 'Intermediate', 'Change Management': 'Level 3', 'Virtual Collaboration': 'Intermediate', 'Data Visualisation': 'Level 3', 'Decision Making': 'Intermediate', 'Partnership Management': 'Level 3', 'Competencies': 'Process Improvement and Optimisation', 'Level 3': 'Technical Sales Support', 'Level 2': 'Stakeholder Management'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "jobs_dict = {}\n",
    "\n",
    "# Retrieve each sector\n",
    "sector_dir_list = [ dir for dir in os.listdir(\"./\") if dir.endswith('_Sector') ]\n",
    "\n",
    "for sector_dir in sector_dir_list:\n",
    "    # Retrieve all subsectors in a sector\n",
    "    subsector_dir_list = [ dir for dir in os.listdir(f\"./{sector_dir}\") ]\n",
    "\n",
    "    for subsector_dir in subsector_dir_list:\n",
    "        # Retrieve all html files in a subsector\n",
    "        html_files = [ file for file in os.listdir(f\"./{sector_dir}/{subsector_dir}/html\") if file.endswith(\".html\") ]\n",
    "\n",
    "        # Scrape each file\n",
    "        for file in html_files:\n",
    "            with open( f\"./{sector_dir}/{subsector_dir}/html/{file}\" ) as fp:\n",
    "                soup = BeautifulSoup(fp, 'html.parser')\n",
    "                all_spans = soup.find_all('span')\n",
    "                \n",
    "                # Retrieve job role\n",
    "                job_role = retrieve_job_role( all_spans )\n",
    "\n",
    "                # Retrieve job's skills and competencies\n",
    "                skills_list = retrieve_skills( all_spans )\n",
    "                \n",
    "                # Create key-value pair -> job_role, skill_list\n",
    "                print(sector_dir, subsector_dir[3:], job_role, skills_list, end = \"\\n\\n\")\n",
    "                break\n",
    "        break\n",
    "    break\n",
    "    \n",
    "\n",
    "# Remember to convert Beginner = Level 1, Intermediate = Level 2, Advanced = Level 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Budgeting': 'Level 3',\n",
       " 'Leadership': 'Intermediate',\n",
       " 'Business Innovation': 'Level 4',\n",
       " 'Developing People': 'Intermediate',\n",
       " 'Business Needs Analysis': 'Level 2',\n",
       " 'Computational Thinking': 'Intermediate',\n",
       " 'Business Performance Management': 'Level 3',\n",
       " 'Communication': 'Intermediate',\n",
       " 'Data Analytics': 'Level 2',\n",
       " 'Creative Thinking': 'Intermediate',\n",
       " 'Data Engineering': 'Level 2',\n",
       " 'Data Ethics': 'Level 3',\n",
       " 'Data Visualisation': 'Level 3',\n",
       " 'Database Administration': 'Level 2',\n",
       " 'Design Thinking Practice': 'Level 3',\n",
       " 'Networking': 'Level 3',\n",
       " 'Project Management': 'Level 3',\n",
       " 'Stakeholder Management': 'Level 2'}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_dict['Data Analyst/Associate Data Engineer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DO BE DONE\n",
    "#         # Retrieve job's key task\n",
    "#         all_td = soup.find_all('td')\n",
    "#         start_index = 0\n",
    "#         end_index = 0\n",
    "\n",
    "#         # Find range of <td> tags that contain job description information\n",
    "#         for i in range( len(all_td) ):\n",
    "#             row_td = all_td[i]\n",
    "\n",
    "# #             if \"Performance Expectations\" in row_td.p:\n",
    "# #                 print(row_td.p)\n",
    "#             print( row_td.p.string )\n",
    "\n",
    "# #             for span in p_tag:\n",
    "# #                 span_text = span.text.strip()\n",
    "# #                 if \"Performance Expectations\" == span_text:\n",
    "# #                     start_index = i + 1\n",
    "\n",
    "# #                 if \"Skills and Competencies\" == span_text:\n",
    "# #                     end_index = i\n",
    "\n",
    "#         # Extract <p> tags that contain job description\n",
    "#         job_desc_list = all_p[start_index:end_index]\n",
    "\n",
    "#         print( job_desc_list )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a63b5797056bf5c56f19e340cdcac44924796f3f1abf887e1d9f6e1bcc845c52"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
