{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IS434: Social Analytics & Apps\n",
    "### SkillsFuture Industry Scraper\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from docx2python import docx2python\n",
    "import json\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions for Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df( df ):\n",
    "    # Clean first column\n",
    "    df.iloc[:, 0] = df.iloc[:, 0].apply( lambda val : str(val[0]) )\n",
    "\n",
    "    # Clean sector, track, subtrack, occupation, job role and JD\n",
    "    for i in range(1, 8):\n",
    "        df.at[i, 1] = [ elem for elem in df.at[i, 1] if elem != \"\" ]\n",
    "        df.at[i, 1] = \"\\n\\n\".join(df.at[i, 1]) # only for job description, the rest are single element lists\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_unicode( string ):\n",
    "    if \"\\u2018\" in string:\n",
    "        string = string.replace(\"\\u2018\", \"\\'\")\n",
    "    if \"\\u2019\" in string:\n",
    "        string = string.replace(\"\\u2019\", \"\\'\")\n",
    "    if \"\\u201c\" in string:\n",
    "        string = string.replace(\"\\u201c\", \"\\\"\")\n",
    "    if \"\\u201d\" in string:\n",
    "        string = string.replace(\"\\u201d\", \"\\\"\")\n",
    "    if \"\\u00a0\" in string:\n",
    "        string = string.replace(\"\\u00a0\", \"\")\n",
    "    if \"\\u2013\" in string:\n",
    "        string = string.replace(\"\\u2013\", \"-\")\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_job_tasks( df ):\n",
    "    # JD info is between columns [Critical Work Functions + Key Tasks] and [Technical Skills and Competencies + Generic Skills and Competencies]\n",
    "    # Step 1: Dynamically retrieve starting and ending index where heading [Critical Work Function] is\n",
    "    start = 0\n",
    "    end = 0\n",
    "\n",
    "    for i in range( df.shape[0] ):\n",
    "        value = df.at[i, 1]\n",
    "        if value != \"\" and value != None:\n",
    "            if \"Critical Work Function\" in value:\n",
    "                start = i + 1 # because next line is where the first CWF is\n",
    "            elif \"Technical Skills and Competencies\" in value:\n",
    "                end = i # python stops 1 val before stated index, so no subtracting required\n",
    "\n",
    "    # Step 2: Slice the dataframe into those with job_skills data only\n",
    "    jd_df = df.iloc[start:end, 1:3]\n",
    "    end = jd_df.shape[0]\n",
    "\n",
    "    # Step 3: Go through the range and find the indexes where each Critical Work Function starts\n",
    "    indexes_list = []\n",
    "    for i in range( jd_df.shape[0] ):\n",
    "        if jd_df.iloc[i, 0] != ['']:\n",
    "            indexes_list.append( i )\n",
    "\n",
    "    # Step 4: For each critical work function, append the key tasks into the dictionary \n",
    "    i = 0\n",
    "    data_dict = {}\n",
    "    \n",
    "    for index in indexes_list:\n",
    "        # 3\n",
    "        critical_work_function = jd_df.iloc[index, 0]\n",
    "\n",
    "        if type(critical_work_function) == str:\n",
    "            critical_work_function = critical_work_function\n",
    "        elif type(critical_work_function) == list:\n",
    "            if len(critical_work_function) == 1:\n",
    "                critical_work_function = critical_work_function[0]\n",
    "            else:\n",
    "                critical_work_function = \"\".join(critical_work_function)\n",
    "\n",
    "        if index == indexes_list[-1]:\n",
    "            # if it is the last element in the indexes_list, it should scrape till the end of the dataframe\n",
    "            key_tasks = [ task[0] for task in jd_df.iloc[ index : end, 1] ]\n",
    "        else:\n",
    "            # else, scrape from the current row till one row before the next critical work function\n",
    "            next_index = indexes_list[i+1]\n",
    "            key_tasks = [ task[0] for task in jd_df.iloc[ index : next_index, 1] ]\n",
    "\n",
    "        # Clean some unicode quotation marks from the code\n",
    "        critical_work_function = clean_unicode( critical_work_function )\n",
    "        key_tasks_cleaned = [ clean_unicode(task) for task in key_tasks ]\n",
    "        data_dict[ critical_work_function ] = key_tasks_cleaned\n",
    "        i += 1\n",
    "    \n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_job_skills( df ):\n",
    "    # Step 1: Dynamically retrieve indexes where section [Skills and Competencies] starts and ends\n",
    "    start = 0\n",
    "    end = 0\n",
    "\n",
    "    for i in range( df.shape[0] ):\n",
    "        value = df.at[i, 0]\n",
    "        if value != \"\" and value != None:\n",
    "            if \"skills and competencies\" in value.lower():\n",
    "                start = i + 1 # because next line is where the first CWF is\n",
    "            elif \"programme\" in value.lower() and \"listing\" in value.lower():\n",
    "                end = i # python stops 1 val before stated index, so no subtracting required\n",
    "\n",
    "    # Step 2: Slice the dataframe into those with Job's Skills data only\n",
    "    skills_df = df.iloc[start:end, 1:].reset_index(drop=True)\n",
    "    skills_df.columns = ['technical_skill', 'tsc_level', 'generic_skill', 'gsc_level']\n",
    "\n",
    "    # Step 3: Clean columns\n",
    "    def clean_tsc_level( level ):\n",
    "        # Some jobs have 2 levels e.g. Level 4, Level 5\n",
    "        # We will only keep the lower requirement\n",
    "        if len( level ) == len(\"Level X\"):\n",
    "            return \"L\" + level[0][-1]\n",
    "        else:\n",
    "            lower_level = level[0].split(\",\")\n",
    "            return \"L\" + lower_level[0][-1]\n",
    "\n",
    "    skills_df['tsc_level'] = skills_df['tsc_level'].apply( clean_tsc_level ) # convert from e.g. Level 4 -> L4\n",
    "    skills_df['gsc_level'] = skills_df['gsc_level'].apply( lambda level : level[0] if level != None else \"\")\n",
    "    skills_df['technical_skill'] = skills_df['technical_skill'].apply( lambda skill : skill[0] ) # remove list\n",
    "    skills_df['generic_skill'] = skills_df['generic_skill'].apply( lambda skill : skill[0] )\n",
    "\n",
    "    # Step 4: Scrape Technical Skills\n",
    "    technical_dict = {}\n",
    "\n",
    "    for _, row in skills_df[['technical_skill', 'tsc_level']].iterrows():\n",
    "        technical_skill = clean_unicode( row['technical_skill'] )\n",
    "        technical_dict[ technical_skill ] = row['tsc_level']\n",
    "\n",
    "    # Step 5: Scrape Generic Skills\n",
    "    generic_dict = {}\n",
    "    for _, row in skills_df[['generic_skill', 'gsc_level']].iterrows():\n",
    "        if row['generic_skill'] == \"\":\n",
    "            break\n",
    "        else:\n",
    "            generic_skill = clean_unicode( row['generic_skill'] )\n",
    "            generic_dict[ generic_skill ] = row['gsc_level']\n",
    "    \n",
    "    return technical_dict, generic_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape Job Description + Job Skills (Technical + Generic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_dir_list = [ dir for dir in os.listdir(\"./\") if \"_Sector\" in dir ]\n",
    "\n",
    "job_id = 0\n",
    "\n",
    "for sector_dir in sector_dir_list:\n",
    "    # retrieve each sector's subfolder\n",
    "    skill_dir_list = [ dir for dir in os.listdir(f\"./{sector_dir}/\") ]\n",
    "    for skill_dir in skill_dir_list:\n",
    "        # retrieve each .docx in a subfolder\n",
    "        docx_files_list = [ docx for docx in os.listdir(f\"./{sector_dir}/{skill_dir}/\") if docx.endswith(\".docx\") ]\n",
    "\n",
    "        # scrape data from each .docx file\n",
    "        for doc_file in docx_files_list:\n",
    "            # Load the file\n",
    "            doc = docx2python(f\"./{sector_dir}/{skill_dir}/{doc_file}\")\n",
    "            table = doc.body[0]\n",
    "            df = clean_df( pd.DataFrame(table) )\n",
    "\n",
    "            # Instantiate dictionary to store job's information\n",
    "            # job_id += 1\n",
    "            job_dict = {\n",
    "                # \"id\": job_id,\n",
    "                \"sector\": \"\",\n",
    "                \"track\": \"\",\n",
    "                \"subtrack\": \"\",\n",
    "                \"job_role\": \"\",\n",
    "                \"description\": \"\",\n",
    "                \"critical_work_functions\" : [],\n",
    "                \"technical_sc\": [],\n",
    "                \"generic_sc\": []\n",
    "            }\n",
    "\n",
    "            # === PART A: Scrape Job Role and Industry Information ===\n",
    "            for _, row in df.iterrows():\n",
    "                heading = row[0]\n",
    "                if heading == 'Sector':\n",
    "                    job_dict['sector'] = row[1]\n",
    "                elif heading == 'Track':\n",
    "                    job_dict['track'] = row[1]\n",
    "                elif heading == \"Sub-track\":\n",
    "                    job_dict['subtrack'] = row[1]\n",
    "                elif heading == 'Job Role':\n",
    "                    job_dict['job_role'] = row[1]\n",
    "                elif heading == 'Job Role Description':\n",
    "                    job_dict['description'] = clean_unicode( row[1] )\n",
    "\n",
    "            # === PART B: Scrape Job Descriptions ===\n",
    "            job_tasks_dict = scrape_job_tasks( df )\n",
    "            job_dict['critical_work_functions'] = job_tasks_dict\n",
    "\n",
    "            # === PART C: Scrape Job Skills ===\n",
    "            technical_skills_dict, generic_skills_dict = scrape_job_skills( df )\n",
    "            job_dict['technical_sc'] = technical_skills_dict\n",
    "            job_dict['generic_sc'] = generic_skills_dict\n",
    "\n",
    "            scraped_data.append( job_dict )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write output to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('jobs_info.json', 'w') as outfile:\n",
    "    outfile.write( json.dumps( scraped_data, indent = 4) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('jobs_info_with_id.json', 'w') as outfile:\n",
    "#     outfile.write( json.dumps( scraped_data, indent = 4) )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a63b5797056bf5c56f19e340cdcac44924796f3f1abf887e1d9f6e1bcc845c52"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
